"""
Author:         Alex Yoo
Date:           November 2018
File:           unsupervised_labels_ft.py

This file will take candidate labels and give the best labels from them using unsupervised way which is just going
to be based on fasttext ranking. 
"""

import pandas as pd
import numpy as np
import re
from scipy.spatial.distance import cosine
from collections import defaultdict, Counter
import argparse

from gensim.models import FastText as ft

# Creating the model
en_model=ft.load_fasttext_format("pre_trained_models/wiki.en/wiki.en.bin")

print "Fasttext model has been loaded"

# The Arguments which were giben in get_labels.py file.
parser = argparse.ArgumentParser()
parser.add_argument("num_unsup_labels") # The number of unsupervised labels.
parser.add_argument("data") # The topic data file. It contains topic terms.
parser.add_argument("output_candidates") # The file which contains candidate labels.
parser.add_argument("output_unsupervised") # The file in which output is written
args = parser.parse_args()


# Get the candidate labels form candidate labels generated by cand-generation(get_labels -cg mode)
label_list =[]
with open(args.output_candidates,'r') as k:
    for line in k:
        labels = line.split()
        label_list.append(labels[1:])

# Just get the number of labels per topic.
test_chunk_size = len(label_list[0])


# Number of Unupervised labels needed should not be less than the number of candidate labels
if test_chunk_size < int(args.num_unsup_labels):
    print "\n"
    print "Error"
    print "You cannot extract more labels than present in input file"
    sys.exit()

# Reading in the topic terms from the topics file.
topics = pd.read_csv(args.data)
try:
    new_frame= topics.drop('domain',1)
    topic_list = new_frame.set_index('topic_id').T.to_dict('list')
except:
    topic_list = topics.set_index('topic_id').T.to_dict('list')
print "Data Gathered for unsupervised model"
print "\n"

"""
This method will be used to get letter trigrams for candidate labels and then rank them.
It uses cosine similarity to get a score between a letter trigram vector of label candidate and vector of
topic terms.The ranks are given based on that score. Based on this rank It will give the best 
unsupervised labels.
"""

def get_best_label(label_list,num):
    top_topic_terms = topic_list[num]
    val_dict = {}
    for label in label_list:
        val = 0.0

        for term in top_topic_terms:
            val += en_model.wv.similarity(label, term) # Cosine Similarity

        val /= len(top_topic_terms) # average
        val_dict[label] = val

    list_sorted=sorted(val_dict.items(), key=lambda x:x[1], reverse = True) # Sorting the labels by rank
    return [i[0] for i in list_sorted[:int(args.num_unsup_labels)]]

unsup_output =[]

import sys 
reload(sys)
sys.setdefaultencoding('utf8') # fix for UnicodeDecodeError

for j in range(len(topic_list)):
    unsup_output.append(get_best_label(label_list[j],j))


# printing the top unsupervised labels.
print "Printing labels for unsupervised model"
print "\n"
g = open(args.output_unsupervised,'w')
for i,item in enumerate(unsup_output):
    print "Top " +args.num_unsup_labels+ " labels for topic " +str(i) +" are:"
    g.write("Top " +args.num_unsup_labels+ " labels for topic " +str(i) +" are:" +"\n")
    for elem in item:
        print elem
        g.write(elem +"\n")
    print "\n"
    g.write("\n")
g.close()


